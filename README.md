# Private Evolution Papers, Code Repositories, and Blogs

[Private Evolution (PE)](https://arxiv.org/abs/2305.15560) is a training-free algorithm for generating differentially private (DP) synthetic data. Unlike traditional methods that require DP fine-tuning of a pre-trained generative model:

* __PE requires no training__ â€” it only utilizes the __inference APIs__ of foundation models or non-neural-network data synthesis tools. This allows PE to take advantage of any cutting-edge API-based foundation models (e.g., GPT-4), open-source models (e.g., Stable Diffusion, Llama), or tools (e.g., computer graphics-based image synthesis tools).

* PE can even __match or outperform state-of-the-art__ training-based methods in balancing data quality with DP guarantees in some cases.

This repository collects papers, code repositories, and blogs related to PE. If you'd like to add your work to the list, feel free to __submit a pull request__, __open an issue__, or __contact me__ (zinanlin AT microsoft.com).


| <sub>Title</sub>                                                                                          | <sub>Year</sub> | <sub>Venue</sub>                                                                           | <sub>Name</sub>                                                    | <sub>Summary</sub>                                                                                                                               | <sub>Links</sub>                                                                                                                                                                                                 | <sub>Organizations</sub>                                                                                             | <sub>Authors</sub>                                                                                                                                                     |
|-----------------------------------------------------------------------------------------------------------|-----------------|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| <sub>Differentially Private Synthetic Data via Foundation Model APIs 1: Images</sub>                      | <sub>2023</sub> | <sub>ICLR 2024, NeurIPS Workshop 2023 __(Oral)__</sub>                                     | <sub>Private Evolution (PE)</sub>                                  | <sub>PE for images</sub>                                                                                                                         | <sub>[[arxiv]](https://arxiv.org/abs/2305.15560) <br /><br />[[code (Private Evolution library)]](https://github.com/microsoft/DPSDA)</sub>                                                                      | <sub>MSR</sub>                                                                                                       | <sub>Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Harsha Nori, Sergey Yekhanin</sub>                                                                                 |
| <sub>Differentially Private Synthetic Data via Foundation Model APIs 2: Text</sub>                        | <sub>2024</sub> | <sub>ICML 2024 __(Spotlight)__, ICLR Workshop 2024</sub>                                   | <sub>Aug-PE</sub>                                                  | <sub>PE for text</sub>                                                                                                                           | <sub>[[arxiv]](https://arxiv.org/abs/2403.01749) <br /><br />[[code (original)]](https://github.com/AI-secure/aug-pe) <br /><br />[[code (Private Evolution library)]](https://github.com/microsoft/DPSDA)</sub> | <sub>MSR, UIUC, UChicago</sub>                                                                                       | <sub>Chulin Xie, Zinan Lin, Arturs Backurs, Sivakanth Gopi, Da Yu, Huseyin Inan, Harsha Nori, Haotian Jiang, Huishuai Zhang, Yin Tat Lee, Bo Li, Sergey Yekhanin</sub> |
| <sub>PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs</sub>                | <sub>2024</sub> | <sub>ICML 2024 __(Oral)__, ICLR Workshop 2024 __(Honorable Mention for Best Paper)__</sub> | <sub>PrE-Text</sub>                                                | <sub>PE for text in federated learning</sub>                                                                                                     | <sub>[[arxiv]](https://arxiv.org/pdf/2406.02958) <br /><br />[[code]](https://github.com/houcharlie/PrE-Text)</sub>                                                                                              | <sub>Meta, CMU</sub>                                                                                                 | <sub>Charlie Hou, Akshat Shrivastava, Hongyuan Zhan, Rylan Conway, Trang Le, Adithya Sagar, Giulia Fanti, Daniel Lazar</sub>                                           |
| <sub>CoAutoGen: Cloud-Edge Collaboration Platform for Automated Synthetic Dataset Generation</sub>        | <sub>2024</sub> | <sub>Code repo</sub>                                                                       | <sub>CoAutoGen</sub>                                               | <sub>PE with cloud-edge collaboration</sub>                                                                                                      | <sub>[[code]](https://github.com/TsingZ0/CoAutoGen)</sub>                                                                                                                                                        | <sub>Shanghai Jiao Tong University</sub>                                                                             | <sub>Jianqing Zhang</sub>                                                                                                                                              |
| <sub>The Crossroads of Innovation and Privacy: Private Synthetic Data for Generative AI</sub>             | <sub>2024</sub> | <sub>Blog</sub>                                                                            | <sub>-</sub>                                                       | <sub>Overview of PE</sub>                                                                                                                        | <sub>[[blog]](https://www.microsoft.com/en-us/research/blog/the-crossroads-of-innovation-and-privacy-private-synthetic-data-for-generative-ai/)</sub>                                                            | <sub>MSR</sub>                                                                                                       | <sub>Gbola Afonja, Robert Sim, Zinan Lin, Huseyin Atahan Inan, Sergey Yekhanin </sub>                                                                                  |
| <sub>Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion</sub>                               | <sub>2025</sub> | <sub>ICML 2025</sub>                                                                       | <sub>WASP</sub>                                                    | <sub>PE with multiple LLMs</sub>                                                                                                                 | <sub>[[arxiv]](https://arxiv.org/abs/2502.00245) <br /><br />[[code]](https://anonymous.4open.science/r/WASP)</sub>                                                                                              | <sub>Tsinghua University, Shanghai Jiao Tong University, Harbin Institute of Technology, AsiaInfo Technologies</sub> | <sub>Tianyuan Zou, Yang Liu, Peng Li, Yufei Xiong, Jianqing Zhang, Jingjing Liu, Xiaozhou Ye, Ye Ouyang, Ya-Qin Zhang</sub>                                            |
| <sub>Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model</sub> | <sub>2025</sub> | <sub>ICLR Workshop 2025</sub>                                                              | <sub>Sim-PE</sub>                                                  | <sub>PE for images using simulators such as text renderer, computer graphics-based render, cartoon avatar generator</sub>                        | <sub>[[arxiv]](https://arxiv.org/abs/2502.05505) <br /><br />[[code (Private Evolution library)]](https://github.com/microsoft/DPSDA)</sub>                                                                      | <sub>MSR</sub>                                                                                                       | <sub>Zinan Lin, Tadas Baltrusaitis, Sergey Yekhanin</sub>                                                                                                              |
| <sub>Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?</sub>                    | <sub>2025</sub> | <sub>-</sub>                                                                               | <sub>-</sub>                                                       | <sub>PE for tabular data</sub>                                                                                                                   | <sub>[[arxiv]](https://arxiv.org/abs/2502.06555)</sub>                                                                                                                                                           | <sub>Google, Boston University</sub>                                                                                 | <sub>Marika Swanberg, Ryan McKenna, Edo Roth, Albert Cheu, Peter Kairouz</sub>                                                                                         |
| <sub>Understanding Aggregate Trends for Apple Intelligence Using Differential Privacy</sub>               | <sub>2025</sub> | <sub>Blog</sub>                                                                            | <sub>-</sub>                                                       | <sub>PE for understanding trends in real user data</sub>                                                                                         | <sub>[[blog]](https://machinelearning.apple.com/research/differential-privacy-aggregate-trends)</sub>                                                                                                            | <sub>Apple</sub>                                                                                                     | <sub>-</sub>                                                                                                                                                           |
| <sub>Private Federated Learning using Preference-Optimized Synthetic Data</sub>                           | <sub>2025</sub> | <sub>ICML 2025, ICLR Workshop 2025 __(Honorable Mention, Spotlight)__</sub>                | <sub>Preference Optimization for Private Client Data (POPri)</sub> | <sub>DP federated learning by fine-tuning LLMs using Direct Preference Optimization (DPO) on preference data collected from clients via PE</sub> | <sub>[[arxiv]](https://arxiv.org/abs/2504.16438) <br /><br />[[code]](https://github.com/meiyuw/POPri)</sub>                                                                                                     | <sub>CMU, Pittsburgh Supercomputing Center, Coldrays</sub>                                                           | <sub>Charlie Hou, Mei-Yu Wang, Yige Zhu, Daniel Lazar, Giulia Fanti</sub>                                                                                              |

